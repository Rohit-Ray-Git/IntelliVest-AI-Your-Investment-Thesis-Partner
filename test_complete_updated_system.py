"""
ğŸ§ª Test Complete Updated Agentic AI System
==========================================

This script tests the complete updated agentic AI system with:
- Primary Model: Gemini 2.5 Flash
- Primary Fallback: Groq DeepSeek R1 Distill Llama-70B
- Secondary Fallback: Groq Llama 3.3-70B Versatile
- Advanced Fallback System Integration
- CrewAI Agents with Updated Models
"""

import os
import sys
import asyncio
import time
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

def test_advanced_fallback_system():
    """Test the advanced fallback system"""
    print("ğŸ” Testing Advanced Fallback System...")
    
    try:
        from llm.advanced_fallback_system import AdvancedFallbackSystem, TaskType
        
        # Create fallback system
        fallback_system = AdvancedFallbackSystem()
        
        # Check configuration
        print(f"âœ… Advanced fallback system initialized with {len(fallback_system.models)} models")
        print(f"ğŸ¯ Primary Model: Gemini 2.5 Flash")
        print(f"ğŸ”„ Primary Fallback: Groq DeepSeek R1 Distill Llama-70B")
        print(f"ğŸ”„ Secondary Fallback: Groq Llama 3.3-70B Versatile")
        
        # Test fallback chains
        for task_type in TaskType:
            chain = fallback_system.fallback_chains[task_type]
            primary = fallback_system.models[chain[0]].name
            primary_fallback = fallback_system.models[chain[1]].name
            print(f"   {task_type.value}: {primary} â†’ {primary_fallback} â†’ ...")
        
        return True
        
    except Exception as e:
        print(f"âŒ Advanced fallback system test failed: {e}")
        return False

def test_crewai_agents():
    """Test CrewAI agents with updated configuration"""
    print("\nğŸ¤– Testing CrewAI Agents with Updated Configuration...")
    
    try:
        from agents.crew_agents_with_tools import InvestmentAnalysisCrewWithTools
        
        # Create crew
        crew = InvestmentAnalysisCrewWithTools()
        
        # Check agents
        agents = [
            crew.researcher,
            crew.sentiment_analyst,
            crew.valuation_analyst,
            crew.thesis_writer,
            crew.critic
        ]
        
        print(f"âœ… Created {len(agents)} agents with advanced fallback system")
        
        # Check if agents have LLM instances
        for i, agent in enumerate(agents):
            if hasattr(agent, 'llm') and agent.llm:
                print(f"   Agent {i+1}: {agent.role} - LLM configured")
            else:
                print(f"   Agent {i+1}: {agent.role} - LLM not configured")
                return False
        
        return True
        
    except Exception as e:
        print(f"âŒ CrewAI agents test failed: {e}")
        return False

def test_custom_tools():
    """Test custom tools integration"""
    print("\nğŸ› ï¸ Testing Custom Tools Integration...")
    
    try:
        from tools.investment_tools import (
            WebCrawlerTool,
            FinancialDataTool,
            SentimentAnalysisTool,
            ValuationTool,
            ThesisGenerationTool,
            CritiqueTool
        )
        
        # Test tool creation
        tools = [
            WebCrawlerTool(),
            FinancialDataTool(),
            SentimentAnalysisTool(),
            ValuationTool(),
            ThesisGenerationTool(),
            CritiqueTool()
        ]
        
        print(f"âœ… Created {len(tools)} custom tools")
        
        # Check tool names
        tool_names = [tool.name for tool in tools]
        expected_names = [
            "web_crawler",
            "financial_data",
            "sentiment_analysis", 
            "valuation",
            "thesis_generation",
            "critique"
        ]
        
        for name in expected_names:
            if name in tool_names:
                print(f"   âœ… {name} tool available")
            else:
                print(f"   âŒ {name} tool missing")
                return False
        
        return True
        
    except Exception as e:
        print(f"âŒ Custom tools test failed: {e}")
        return False

async def test_model_execution():
    """Test model execution with new configuration"""
    print("\nğŸš€ Testing Model Execution with New Configuration...")
    
    try:
        from llm.advanced_fallback_system import AdvancedFallbackSystem, TaskType
        
        # Create fallback system
        fallback_system = AdvancedFallbackSystem()
        
        # Test with different task types
        test_cases = [
            ("Provide a brief overview of Tesla Inc.", TaskType.RESEARCH),
            ("Analyze sentiment: 'Tesla reported record quarterly deliveries.'", TaskType.SENTIMENT),
            ("Create a simple investment thesis for Microsoft", TaskType.THESIS)
        ]
        
        for prompt, task_type in test_cases:
            print(f"\nğŸ§ª Testing {task_type.value} task...")
            print(f"ğŸ“ Prompt: {prompt[:50]}...")
            
            try:
                # Execute with fallback
                result = await fallback_system.execute_with_fallback(
                    prompt, 
                    task_type, 
                    max_fallbacks=2
                )
                
                # Check results
                if result.content and result.content != "All LLM attempts failed. Please check your API keys and network connection.":
                    print(f"âœ… {task_type.value} task completed successfully")
                    print(f"   Model: {result.model_used}")
                    print(f"   Time: {result.response_time:.2f}s")
                    print(f"   Confidence: {result.confidence_score:.2f}")
                    print(f"   Fallbacks: {result.fallback_count}")
                    
                    # Check if the model used is one of our new models
                    new_model_names = [
                        "Gemini 2.5 Flash",
                        "Groq DeepSeek R1 Distill Llama-70B",
                        "Groq Llama 3.3-70B Versatile"
                    ]
                    
                    if any(name in result.model_used for name in new_model_names):
                        print(f"   ğŸ¯ Successfully used new model: {result.model_used}")
                    else:
                        print(f"   âš ï¸ Used fallback model: {result.model_used}")
                    
                else:
                    print(f"âš ï¸ {task_type.value} task failed (likely API key issue)")
                    print(f"   Errors: {result.errors}")
                
            except Exception as e:
                print(f"âŒ {task_type.value} task failed: {e}")
                return False
        
        return True
        
    except Exception as e:
        print(f"âŒ Model execution test failed: {e}")
        return False

def test_system_integration():
    """Test complete system integration"""
    print("\nğŸ”— Testing Complete System Integration...")
    
    try:
        # Test all components together
        from llm.advanced_fallback_system import AdvancedFallbackSystem
        from agents.crew_agents_with_tools import InvestmentAnalysisCrewWithTools
        from tools.investment_tools import WebCrawlerTool, FinancialDataTool
        
        # Create fallback system
        fallback_system = AdvancedFallbackSystem()
        print("âœ… Advanced fallback system created")
        
        # Create crew
        crew = InvestmentAnalysisCrewWithTools()
        print("âœ… CrewAI agents created with advanced fallback")
        
        # Create tools
        web_crawler = WebCrawlerTool()
        financial_data = FinancialDataTool()
        print("âœ… Custom tools created")
        
        # Check integration
        if hasattr(crew, 'fallback_system'):
            print("âœ… CrewAI integrated with advanced fallback system")
        else:
            print("âŒ CrewAI not integrated with advanced fallback system")
            return False
        
        if hasattr(crew, 'tools'):
            print("âœ… CrewAI integrated with custom tools")
        else:
            print("âŒ CrewAI not integrated with custom tools")
            return False
        
        return True
        
    except Exception as e:
        print(f"âŒ System integration test failed: {e}")
        return False

async def test_complete_workflow():
    """Test complete workflow with updated system"""
    print("\nğŸ”„ Testing Complete Workflow with Updated System...")
    
    try:
        from agents.crew_agents_with_tools import InvestmentAnalysisCrewWithTools
        
        # Create crew
        crew = InvestmentAnalysisCrewWithTools()
        
        # Test with a simple company
        company_name = "Apple Inc."
        print(f"ğŸ§ª Testing complete workflow with: {company_name}")
        
        # Run analysis
        start_time = time.time()
        result = await crew.run_analysis(company_name)
        execution_time = time.time() - start_time
        
        # Check results
        print(f"â±ï¸ Workflow executed in {execution_time:.2f} seconds")
        print(f"ğŸ“Š Status: {result['status']}")
        
        if result['status'] == 'success':
            print("âœ… Complete workflow successful!")
            print(f"ğŸ¯ Primary Model: {result.get('primary_model', 'Unknown')}")
            print(f"ğŸ”„ Fallback Models: {result.get('fallback_models', [])}")
            print(f"ğŸ¤– Agents Used: {len(result.get('agents_used', []))}")
            print(f"ğŸ› ï¸ Fallback System: {result.get('fallback_system', 'Unknown')}")
            
            return True
        else:
            print(f"âŒ Complete workflow failed: {result.get('error', 'Unknown error')}")
            return False
            
    except Exception as e:
        print(f"âŒ Complete workflow test failed: {e}")
        return False

async def main():
    """Run all complete system tests"""
    print("ğŸ¯ Complete Updated Agentic AI System - Comprehensive Test")
    print("=" * 70)
    
    tests = [
        ("Advanced Fallback System Test", test_advanced_fallback_system),
        ("CrewAI Agents Test", test_crewai_agents),
        ("Custom Tools Test", test_custom_tools),
        ("System Integration Test", test_system_integration),
        ("Model Execution Test", test_model_execution),
        ("Complete Workflow Test", test_complete_workflow)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\nğŸ“‹ Running {test_name}...")
        try:
            if asyncio.iscoroutinefunction(test_func):
                result = await test_func()
            else:
                result = test_func()
            
            if result:
                passed += 1
                print(f"âœ… {test_name} PASSED")
            else:
                print(f"âŒ {test_name} FAILED")
        except Exception as e:
            print(f"âŒ {test_name} FAILED with exception: {e}")
    
    print("\n" + "=" * 70)
    print(f"ğŸ“Š Test Results: {passed}/{total} tests passed")
    
    if passed == total:
        print("ğŸ‰ All complete system tests passed!")
        print("\nğŸš€ Complete Updated Agentic AI System Capabilities:")
        print("   âœ… Primary Model: Gemini 2.5 Flash")
        print("   âœ… Primary Fallback: Groq DeepSeek R1 Distill Llama-70B")
        print("   âœ… Secondary Fallback: Groq Llama 3.3-70B Versatile")
        print("   âœ… Advanced Fallback System: Multi-LLM orchestration")
        print("   âœ… CrewAI Integration: 5 specialized agents")
        print("   âœ… Custom Tools: 6 tools with real data access")
        print("   âœ… System Integration: Complete workflow orchestration")
        print("   âœ… Production Ready: Robust error handling and monitoring")
        
        print("\nğŸ”„ Updated Fallback Chain:")
        print("   ğŸ¯ Primary: Gemini 2.5 Flash")
        print("   ğŸ”„ Primary Fallback: Groq DeepSeek R1 Distill Llama-70B")
        print("   ğŸ”„ Secondary Fallback: Groq Llama 3.3-70B Versatile")
        print("   ğŸ”„ Tertiary+: Other models as needed")
        
        print("\nğŸ¯ System Architecture:")
        print("   ğŸ¤– CrewAI Framework: Agent orchestration")
        print("   ğŸ§  Advanced Fallback: Multi-LLM intelligence")
        print("   ğŸ› ï¸ Custom Tools: Real data access")
        print("   ğŸ”„ LangGraph: State management (ready)")
        print("   ğŸ“Š Professional Analysis: Complete pipeline")
        
        print("\nğŸš€ Ready for Production with Updated Model Configuration!")
        
        return True
    else:
        print("âš ï¸ Some complete system tests failed. Please check the errors above.")
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1) 